{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# 30 Day Kaggle Challenge\n",
                "## Competition Phase\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Initialize Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 177,
            "source": [
                "#Import thr important packages\n",
                "import pandas as pd\n",
                "import os, datetime\n",
                "\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "from sklearn.metrics import mean_squared_error\n",
                "# for root mean squared error rmse\n",
                "#rms = mean_squared_error(y, X, squared= False)\n",
                "\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.preprocessing import OneHotEncoder"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 178,
            "source": [
                "#Get and Display current working directory\n",
                "cwd = os.getcwd()\n",
                "print(cwd)\n",
                "\n",
                "#Change Directory to parent (one step up)\n",
                "filepath_elements = cwd.split('/')\n",
                "filepath_elements.pop()\n",
                "filepath= '/'.join(filepath_elements)\n",
                "filepath\n",
                "\n",
                "#Save filenames and path as str in variables\n",
                "datapath = '/30-days-of-ml/'\n",
                "dataname_test = 'test.csv'\n",
                "dataname_train = 'train.csv'\n",
                "dataname_samplesubmit = 'sample_submission.csv'\n",
                "\n",
                "#Read the csv files and initialize as Dataframes\n",
                "data_test = pd.read_csv(filepath+datapath+dataname_test, index_col='id')\n",
                "data_train = pd.read_csv(filepath+datapath+dataname_train, index_col='id')\n",
                "data_samplesubmit = pd.read_csv(filepath+datapath+dataname_samplesubmit, index_col='id')"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "/Users/amitavchrismostafa/Documents/Python/kaggle-project/30daykaggle-ml\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Display Data for viewing\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 179,
            "source": [
                "data_samplesubmit.head(10)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "    target\n",
                            "id        \n",
                            "0      0.5\n",
                            "5      0.5\n",
                            "15     0.5\n",
                            "16     0.5\n",
                            "17     0.5\n",
                            "19     0.5\n",
                            "20     0.5\n",
                            "21     0.5\n",
                            "23     0.5\n",
                            "29     0.5"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>target</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>id</th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>0</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>5</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>15</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>16</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>17</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>19</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>20</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>21</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>23</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>29</td>\n",
                            "      <td>0.5</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 179
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 180,
            "source": [
                "data_train.head(10)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont5     cont6  \\\n",
                            "id                                                    ...                       \n",
                            "1     B    B    B    C    B    B    A    E    C    N  ...  0.400361  0.160266   \n",
                            "2     B    B    A    A    B    D    A    F    A    O  ...  0.533087  0.558922   \n",
                            "3     A    A    A    C    B    D    A    D    A    F  ...  0.650609  0.375348   \n",
                            "4     B    B    A    C    B    D    A    E    C    K  ...  0.668980  0.239061   \n",
                            "6     A    A    A    C    B    D    A    E    A    N  ...  0.686964  0.420667   \n",
                            "7     A    B    A    C    B    D    A    E    G    F  ...  0.392432  0.658169   \n",
                            "8     B    A    A    A    B    D    A    E    C    F  ...  0.396705  0.273454   \n",
                            "9     A    A    A    C    B    B    A    E    A    M  ...  0.633353  0.339760   \n",
                            "10    A    B    A    C    B    D    A    E    G    I  ...  0.472564  0.414036   \n",
                            "11    A    A    A    A    B    B    A    E    E    M  ...  0.425716  0.233705   \n",
                            "\n",
                            "       cont7     cont8     cont9    cont10    cont11    cont12    cont13  \\\n",
                            "id                                                                         \n",
                            "1   0.310921  0.389470  0.267559  0.237281  0.377873  0.322401  0.869850   \n",
                            "2   0.516294  0.594928  0.341439  0.906013  0.921701  0.261975  0.465083   \n",
                            "3   0.902567  0.555205  0.843531  0.748809  0.620126  0.541474  0.763846   \n",
                            "4   0.732948  0.679618  0.574844  0.346010  0.714610  0.540150  0.280682   \n",
                            "6   0.648182  0.684501  0.956692  1.000773  0.776742  0.625849  0.250823   \n",
                            "7   0.997473  0.569874  0.960864  0.238050  0.316065  0.731729  0.694719   \n",
                            "8   0.824573  0.656325  0.677114  0.808445  0.615973  0.631677  0.283561   \n",
                            "9   0.802006  1.010997  0.391221  0.057297  0.591120  0.074629  0.775869   \n",
                            "10  0.809142  1.013301  0.761183  1.041711  0.393960  0.782381  0.865610   \n",
                            "11  0.493036  0.353048  0.334675  0.085087  0.230634  0.636732  0.291874   \n",
                            "\n",
                            "      target  \n",
                            "id            \n",
                            "1   8.113634  \n",
                            "2   8.481233  \n",
                            "3   8.364351  \n",
                            "4   8.049253  \n",
                            "6   7.972260  \n",
                            "7   8.028558  \n",
                            "8   7.811465  \n",
                            "9   7.674188  \n",
                            "10  8.090095  \n",
                            "11  8.446155  \n",
                            "\n",
                            "[10 rows x 25 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>cat0</th>\n",
                            "      <th>cat1</th>\n",
                            "      <th>cat2</th>\n",
                            "      <th>cat3</th>\n",
                            "      <th>cat4</th>\n",
                            "      <th>cat5</th>\n",
                            "      <th>cat6</th>\n",
                            "      <th>cat7</th>\n",
                            "      <th>cat8</th>\n",
                            "      <th>cat9</th>\n",
                            "      <th>...</th>\n",
                            "      <th>cont5</th>\n",
                            "      <th>cont6</th>\n",
                            "      <th>cont7</th>\n",
                            "      <th>cont8</th>\n",
                            "      <th>cont9</th>\n",
                            "      <th>cont10</th>\n",
                            "      <th>cont11</th>\n",
                            "      <th>cont12</th>\n",
                            "      <th>cont13</th>\n",
                            "      <th>target</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>id</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>C</td>\n",
                            "      <td>N</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.400361</td>\n",
                            "      <td>0.160266</td>\n",
                            "      <td>0.310921</td>\n",
                            "      <td>0.389470</td>\n",
                            "      <td>0.267559</td>\n",
                            "      <td>0.237281</td>\n",
                            "      <td>0.377873</td>\n",
                            "      <td>0.322401</td>\n",
                            "      <td>0.869850</td>\n",
                            "      <td>8.113634</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>F</td>\n",
                            "      <td>A</td>\n",
                            "      <td>O</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.533087</td>\n",
                            "      <td>0.558922</td>\n",
                            "      <td>0.516294</td>\n",
                            "      <td>0.594928</td>\n",
                            "      <td>0.341439</td>\n",
                            "      <td>0.906013</td>\n",
                            "      <td>0.921701</td>\n",
                            "      <td>0.261975</td>\n",
                            "      <td>0.465083</td>\n",
                            "      <td>8.481233</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>F</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.650609</td>\n",
                            "      <td>0.375348</td>\n",
                            "      <td>0.902567</td>\n",
                            "      <td>0.555205</td>\n",
                            "      <td>0.843531</td>\n",
                            "      <td>0.748809</td>\n",
                            "      <td>0.620126</td>\n",
                            "      <td>0.541474</td>\n",
                            "      <td>0.763846</td>\n",
                            "      <td>8.364351</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>4</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>C</td>\n",
                            "      <td>K</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.668980</td>\n",
                            "      <td>0.239061</td>\n",
                            "      <td>0.732948</td>\n",
                            "      <td>0.679618</td>\n",
                            "      <td>0.574844</td>\n",
                            "      <td>0.346010</td>\n",
                            "      <td>0.714610</td>\n",
                            "      <td>0.540150</td>\n",
                            "      <td>0.280682</td>\n",
                            "      <td>8.049253</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>6</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>A</td>\n",
                            "      <td>N</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.686964</td>\n",
                            "      <td>0.420667</td>\n",
                            "      <td>0.648182</td>\n",
                            "      <td>0.684501</td>\n",
                            "      <td>0.956692</td>\n",
                            "      <td>1.000773</td>\n",
                            "      <td>0.776742</td>\n",
                            "      <td>0.625849</td>\n",
                            "      <td>0.250823</td>\n",
                            "      <td>7.972260</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>7</td>\n",
                            "      <td>A</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>G</td>\n",
                            "      <td>F</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.392432</td>\n",
                            "      <td>0.658169</td>\n",
                            "      <td>0.997473</td>\n",
                            "      <td>0.569874</td>\n",
                            "      <td>0.960864</td>\n",
                            "      <td>0.238050</td>\n",
                            "      <td>0.316065</td>\n",
                            "      <td>0.731729</td>\n",
                            "      <td>0.694719</td>\n",
                            "      <td>8.028558</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>8</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>C</td>\n",
                            "      <td>F</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.396705</td>\n",
                            "      <td>0.273454</td>\n",
                            "      <td>0.824573</td>\n",
                            "      <td>0.656325</td>\n",
                            "      <td>0.677114</td>\n",
                            "      <td>0.808445</td>\n",
                            "      <td>0.615973</td>\n",
                            "      <td>0.631677</td>\n",
                            "      <td>0.283561</td>\n",
                            "      <td>7.811465</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>9</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>A</td>\n",
                            "      <td>M</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.633353</td>\n",
                            "      <td>0.339760</td>\n",
                            "      <td>0.802006</td>\n",
                            "      <td>1.010997</td>\n",
                            "      <td>0.391221</td>\n",
                            "      <td>0.057297</td>\n",
                            "      <td>0.591120</td>\n",
                            "      <td>0.074629</td>\n",
                            "      <td>0.775869</td>\n",
                            "      <td>7.674188</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>10</td>\n",
                            "      <td>A</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>G</td>\n",
                            "      <td>I</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.472564</td>\n",
                            "      <td>0.414036</td>\n",
                            "      <td>0.809142</td>\n",
                            "      <td>1.013301</td>\n",
                            "      <td>0.761183</td>\n",
                            "      <td>1.041711</td>\n",
                            "      <td>0.393960</td>\n",
                            "      <td>0.782381</td>\n",
                            "      <td>0.865610</td>\n",
                            "      <td>8.090095</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>11</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>E</td>\n",
                            "      <td>M</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.425716</td>\n",
                            "      <td>0.233705</td>\n",
                            "      <td>0.493036</td>\n",
                            "      <td>0.353048</td>\n",
                            "      <td>0.334675</td>\n",
                            "      <td>0.085087</td>\n",
                            "      <td>0.230634</td>\n",
                            "      <td>0.636732</td>\n",
                            "      <td>0.291874</td>\n",
                            "      <td>8.446155</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>10 rows × 25 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 180
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 181,
            "source": [
                "data_test.head(10)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont4     cont5  \\\n",
                            "id                                                    ...                       \n",
                            "0     B    B    B    C    B    B    A    E    E    I  ...  0.476739  0.376350   \n",
                            "5     A    B    A    C    B    C    A    E    C    H  ...  0.285509  0.860046   \n",
                            "15    B    A    A    A    B    B    A    E    D    K  ...  0.697272  0.683600   \n",
                            "16    B    B    A    C    B    D    A    E    A    N  ...  0.719306  0.777890   \n",
                            "17    B    B    A    C    B    C    A    E    C    F  ...  0.313032  0.431007   \n",
                            "19    B    B    B    C    B    B    A    E    E    F  ...  0.489711  0.533519   \n",
                            "20    A    A    A    C    B    D    A    E    G    K  ...  0.285503  0.497190   \n",
                            "21    B    B    A    C    B    D    A    E    A    K  ...  0.346929  0.774717   \n",
                            "23    A    A    A    C    B    B    A    E    E    N  ...  0.484546  0.688881   \n",
                            "29    A    A    A    C    B    D    A    E    A    I  ...  0.425122  0.758756   \n",
                            "\n",
                            "       cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\n",
                            "id                                                                         \n",
                            "0   0.337884  0.321832  0.445212  0.290258  0.244476  0.087914  0.301831   \n",
                            "5   0.798712  0.835961  0.391657  0.288276  0.549568  0.905097  0.850684   \n",
                            "15  0.404089  0.879379  0.275549  0.427871  0.491667  0.384315  0.376689   \n",
                            "16  0.730954  0.644315  1.024017  0.391090  0.988340  0.411828  0.393585   \n",
                            "17  0.390992  0.408874  0.447887  0.390253  0.648932  0.385935  0.370401   \n",
                            "19  0.451563  0.513817  0.429349  0.489093  0.326913  0.440908  0.694076   \n",
                            "20  0.540631  0.521383  0.277155  0.837442  0.602099  1.057592  0.522523   \n",
                            "21  0.374756  0.838619  0.641282  0.854445  0.834690  0.347269  0.741068   \n",
                            "23  0.356810  0.732911  0.259619  0.275222  0.750423  0.783911  0.601736   \n",
                            "29  0.706094  0.871956  0.584765  0.550189  0.775375  0.798391  0.972790   \n",
                            "\n",
                            "      cont13  \n",
                            "id            \n",
                            "0   0.845702  \n",
                            "5   0.693940  \n",
                            "15  0.508099  \n",
                            "16  0.461372  \n",
                            "17  0.900412  \n",
                            "19  0.444859  \n",
                            "20  0.668214  \n",
                            "21  0.257963  \n",
                            "23  0.811545  \n",
                            "29  0.283684  \n",
                            "\n",
                            "[10 rows x 24 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>cat0</th>\n",
                            "      <th>cat1</th>\n",
                            "      <th>cat2</th>\n",
                            "      <th>cat3</th>\n",
                            "      <th>cat4</th>\n",
                            "      <th>cat5</th>\n",
                            "      <th>cat6</th>\n",
                            "      <th>cat7</th>\n",
                            "      <th>cat8</th>\n",
                            "      <th>cat9</th>\n",
                            "      <th>...</th>\n",
                            "      <th>cont4</th>\n",
                            "      <th>cont5</th>\n",
                            "      <th>cont6</th>\n",
                            "      <th>cont7</th>\n",
                            "      <th>cont8</th>\n",
                            "      <th>cont9</th>\n",
                            "      <th>cont10</th>\n",
                            "      <th>cont11</th>\n",
                            "      <th>cont12</th>\n",
                            "      <th>cont13</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>id</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>0</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>E</td>\n",
                            "      <td>I</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.476739</td>\n",
                            "      <td>0.376350</td>\n",
                            "      <td>0.337884</td>\n",
                            "      <td>0.321832</td>\n",
                            "      <td>0.445212</td>\n",
                            "      <td>0.290258</td>\n",
                            "      <td>0.244476</td>\n",
                            "      <td>0.087914</td>\n",
                            "      <td>0.301831</td>\n",
                            "      <td>0.845702</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>5</td>\n",
                            "      <td>A</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>C</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>C</td>\n",
                            "      <td>H</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.285509</td>\n",
                            "      <td>0.860046</td>\n",
                            "      <td>0.798712</td>\n",
                            "      <td>0.835961</td>\n",
                            "      <td>0.391657</td>\n",
                            "      <td>0.288276</td>\n",
                            "      <td>0.549568</td>\n",
                            "      <td>0.905097</td>\n",
                            "      <td>0.850684</td>\n",
                            "      <td>0.693940</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>15</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>D</td>\n",
                            "      <td>K</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.697272</td>\n",
                            "      <td>0.683600</td>\n",
                            "      <td>0.404089</td>\n",
                            "      <td>0.879379</td>\n",
                            "      <td>0.275549</td>\n",
                            "      <td>0.427871</td>\n",
                            "      <td>0.491667</td>\n",
                            "      <td>0.384315</td>\n",
                            "      <td>0.376689</td>\n",
                            "      <td>0.508099</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>16</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>A</td>\n",
                            "      <td>N</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.719306</td>\n",
                            "      <td>0.777890</td>\n",
                            "      <td>0.730954</td>\n",
                            "      <td>0.644315</td>\n",
                            "      <td>1.024017</td>\n",
                            "      <td>0.391090</td>\n",
                            "      <td>0.988340</td>\n",
                            "      <td>0.411828</td>\n",
                            "      <td>0.393585</td>\n",
                            "      <td>0.461372</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>17</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>C</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>C</td>\n",
                            "      <td>F</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.313032</td>\n",
                            "      <td>0.431007</td>\n",
                            "      <td>0.390992</td>\n",
                            "      <td>0.408874</td>\n",
                            "      <td>0.447887</td>\n",
                            "      <td>0.390253</td>\n",
                            "      <td>0.648932</td>\n",
                            "      <td>0.385935</td>\n",
                            "      <td>0.370401</td>\n",
                            "      <td>0.900412</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>19</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>E</td>\n",
                            "      <td>F</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.489711</td>\n",
                            "      <td>0.533519</td>\n",
                            "      <td>0.451563</td>\n",
                            "      <td>0.513817</td>\n",
                            "      <td>0.429349</td>\n",
                            "      <td>0.489093</td>\n",
                            "      <td>0.326913</td>\n",
                            "      <td>0.440908</td>\n",
                            "      <td>0.694076</td>\n",
                            "      <td>0.444859</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>20</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>G</td>\n",
                            "      <td>K</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.285503</td>\n",
                            "      <td>0.497190</td>\n",
                            "      <td>0.540631</td>\n",
                            "      <td>0.521383</td>\n",
                            "      <td>0.277155</td>\n",
                            "      <td>0.837442</td>\n",
                            "      <td>0.602099</td>\n",
                            "      <td>1.057592</td>\n",
                            "      <td>0.522523</td>\n",
                            "      <td>0.668214</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>21</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>A</td>\n",
                            "      <td>K</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.346929</td>\n",
                            "      <td>0.774717</td>\n",
                            "      <td>0.374756</td>\n",
                            "      <td>0.838619</td>\n",
                            "      <td>0.641282</td>\n",
                            "      <td>0.854445</td>\n",
                            "      <td>0.834690</td>\n",
                            "      <td>0.347269</td>\n",
                            "      <td>0.741068</td>\n",
                            "      <td>0.257963</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>23</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>E</td>\n",
                            "      <td>N</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.484546</td>\n",
                            "      <td>0.688881</td>\n",
                            "      <td>0.356810</td>\n",
                            "      <td>0.732911</td>\n",
                            "      <td>0.259619</td>\n",
                            "      <td>0.275222</td>\n",
                            "      <td>0.750423</td>\n",
                            "      <td>0.783911</td>\n",
                            "      <td>0.601736</td>\n",
                            "      <td>0.811545</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>29</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>A</td>\n",
                            "      <td>I</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.425122</td>\n",
                            "      <td>0.758756</td>\n",
                            "      <td>0.706094</td>\n",
                            "      <td>0.871956</td>\n",
                            "      <td>0.584765</td>\n",
                            "      <td>0.550189</td>\n",
                            "      <td>0.775375</td>\n",
                            "      <td>0.798391</td>\n",
                            "      <td>0.972790</td>\n",
                            "      <td>0.283684</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>10 rows × 24 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 181
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 182,
            "source": [
                "#Getting Columns\n",
                "train_cols = list(data_train.columns)\n",
                "print(train_cols)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'target']\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 183,
            "source": [
                "test_cols = list(data_test.columns)\n",
                "print(test_cols)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 192,
            "source": [
                "#Inspect for NaNs\n",
                "print(data_train.isnull().sum().sum())\n",
                "data_train.isnull().any();"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 190,
            "source": [
                "print(data_test.isnull().sum().sum())\n",
                "data_test.isnull().any();"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#### \"Cardinality\" means the number of unique values in a column\n",
                "#### Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
                "categorical_cols = [cname for cname in X_train_full.columns if\n",
                "                    X_train_full[cname].nunique() < 10 and \n",
                "                    X_train_full[cname].dtype == \"object\"]\n",
                "\n",
                "#### Select numerical columns\n",
                "numerical_cols = [cname for cname in X_train_full.columns if \n",
                "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
                "\n",
                "#### Keep selected columns only\n",
                "my_cols = categorical_cols + numerical_cols\n",
                "X_train = X_train_full[my_cols].copy()\n",
                "X_valid = X_valid_full[my_cols].copy()\n",
                "X_test = X_test_full[my_cols].copy()\n",
                "\n",
                "\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_absolute_error"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "#### Get number of unique entries in each column with categorical data\n",
                "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
                "d = dict(zip(object_cols, object_nunique))\n",
                "\n",
                "#### Print number of unique entries by column, in ascending order\n",
                "sorted(d.items(), key=lambda x: x[1])\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Approach 1a: Drop all categorical columns"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 186,
            "source": [
                "#Code snippet\n",
                "#dropna data=data.dropna(axis=0) which i think means rows\n",
                "\n",
                "data_train_1a = data_train.copy()\n",
                "\n",
                "\n",
                "#Gain y from train data\n",
                "y_train_1a = data_train_1a.target\n",
                "\n",
                "#features_nocat = [col for col in train_cols if 'cont' in col]\n",
                "#print(features_nocat)\n",
                "\n",
                "#Gain X from train data\n",
                "X_train_1a = data_train_1a.drop(['target'], axis=1) #inlince keeps one copy and makes changes to it instead of making new copes\n",
                "\n",
                "#alternatively\n",
                "#train_cols.pop('target') => maybe this is a thing? Idk haven't checked\n",
                "# X_train = data_train[train_cols]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 187,
            "source": [
                "y_train_1a.head()\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "id\n",
                            "1    8.113634\n",
                            "2    8.481233\n",
                            "3    8.364351\n",
                            "4    8.049253\n",
                            "6    7.972260\n",
                            "Name: target, dtype: float64"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 187
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 188,
            "source": [
                "X_train_1a.head()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont4     cont5  \\\n",
                            "id                                                    ...                       \n",
                            "1     B    B    B    C    B    B    A    E    C    N  ...  0.610706  0.400361   \n",
                            "2     B    B    A    A    B    D    A    F    A    O  ...  0.276853  0.533087   \n",
                            "3     A    A    A    C    B    D    A    D    A    F  ...  0.285074  0.650609   \n",
                            "4     B    B    A    C    B    D    A    E    C    K  ...  0.284667  0.668980   \n",
                            "6     A    A    A    C    B    D    A    E    A    N  ...  0.287595  0.686964   \n",
                            "\n",
                            "       cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\n",
                            "id                                                                         \n",
                            "1   0.160266  0.310921  0.389470  0.267559  0.237281  0.377873  0.322401   \n",
                            "2   0.558922  0.516294  0.594928  0.341439  0.906013  0.921701  0.261975   \n",
                            "3   0.375348  0.902567  0.555205  0.843531  0.748809  0.620126  0.541474   \n",
                            "4   0.239061  0.732948  0.679618  0.574844  0.346010  0.714610  0.540150   \n",
                            "6   0.420667  0.648182  0.684501  0.956692  1.000773  0.776742  0.625849   \n",
                            "\n",
                            "      cont13  \n",
                            "id            \n",
                            "1   0.869850  \n",
                            "2   0.465083  \n",
                            "3   0.763846  \n",
                            "4   0.280682  \n",
                            "6   0.250823  \n",
                            "\n",
                            "[5 rows x 24 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>cat0</th>\n",
                            "      <th>cat1</th>\n",
                            "      <th>cat2</th>\n",
                            "      <th>cat3</th>\n",
                            "      <th>cat4</th>\n",
                            "      <th>cat5</th>\n",
                            "      <th>cat6</th>\n",
                            "      <th>cat7</th>\n",
                            "      <th>cat8</th>\n",
                            "      <th>cat9</th>\n",
                            "      <th>...</th>\n",
                            "      <th>cont4</th>\n",
                            "      <th>cont5</th>\n",
                            "      <th>cont6</th>\n",
                            "      <th>cont7</th>\n",
                            "      <th>cont8</th>\n",
                            "      <th>cont9</th>\n",
                            "      <th>cont10</th>\n",
                            "      <th>cont11</th>\n",
                            "      <th>cont12</th>\n",
                            "      <th>cont13</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>id</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>C</td>\n",
                            "      <td>N</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.610706</td>\n",
                            "      <td>0.400361</td>\n",
                            "      <td>0.160266</td>\n",
                            "      <td>0.310921</td>\n",
                            "      <td>0.389470</td>\n",
                            "      <td>0.267559</td>\n",
                            "      <td>0.237281</td>\n",
                            "      <td>0.377873</td>\n",
                            "      <td>0.322401</td>\n",
                            "      <td>0.869850</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>F</td>\n",
                            "      <td>A</td>\n",
                            "      <td>O</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.276853</td>\n",
                            "      <td>0.533087</td>\n",
                            "      <td>0.558922</td>\n",
                            "      <td>0.516294</td>\n",
                            "      <td>0.594928</td>\n",
                            "      <td>0.341439</td>\n",
                            "      <td>0.906013</td>\n",
                            "      <td>0.921701</td>\n",
                            "      <td>0.261975</td>\n",
                            "      <td>0.465083</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>F</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.285074</td>\n",
                            "      <td>0.650609</td>\n",
                            "      <td>0.375348</td>\n",
                            "      <td>0.902567</td>\n",
                            "      <td>0.555205</td>\n",
                            "      <td>0.843531</td>\n",
                            "      <td>0.748809</td>\n",
                            "      <td>0.620126</td>\n",
                            "      <td>0.541474</td>\n",
                            "      <td>0.763846</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>4</td>\n",
                            "      <td>B</td>\n",
                            "      <td>B</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>C</td>\n",
                            "      <td>K</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.284667</td>\n",
                            "      <td>0.668980</td>\n",
                            "      <td>0.239061</td>\n",
                            "      <td>0.732948</td>\n",
                            "      <td>0.679618</td>\n",
                            "      <td>0.574844</td>\n",
                            "      <td>0.346010</td>\n",
                            "      <td>0.714610</td>\n",
                            "      <td>0.540150</td>\n",
                            "      <td>0.280682</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>6</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>A</td>\n",
                            "      <td>C</td>\n",
                            "      <td>B</td>\n",
                            "      <td>D</td>\n",
                            "      <td>A</td>\n",
                            "      <td>E</td>\n",
                            "      <td>A</td>\n",
                            "      <td>N</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.287595</td>\n",
                            "      <td>0.686964</td>\n",
                            "      <td>0.420667</td>\n",
                            "      <td>0.648182</td>\n",
                            "      <td>0.684501</td>\n",
                            "      <td>0.956692</td>\n",
                            "      <td>1.000773</td>\n",
                            "      <td>0.776742</td>\n",
                            "      <td>0.625849</td>\n",
                            "      <td>0.250823</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 24 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 188
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 189,
            "source": [
                "#### \"Cardinality\" means the number of unique values in a column\n",
                "#### Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
                "categorical_cols = [cname for cname in X_train_full.columns if\n",
                "                    X_train_full[cname].nunique() < 10 and \n",
                "                    X_train_full[cname].dtype == \"object\"]\n",
                "\n",
                "#### Select numerical columns\n",
                "numerical_cols = [cname for cname in X_train_full.columns if \n",
                "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
                "\n",
                "#### Keep selected columns only\n",
                "my_cols = categorical_cols + numerical_cols\n",
                "X_train = X_train_full[my_cols].copy()\n",
                "X_valid = X_valid_full[my_cols].copy()\n",
                "X_test = X_test_full[my_cols].copy()\n",
                "\n",
                "\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_absolute_error"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "name 'b' is not defined",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-189-89e6c98d9288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "## Ansatz1\n",
                "#### Specify Model\n",
                "iowa_model = DecisionTreeRegressor()\n",
                "#### Fit Model\n",
                "iowa_model.fit(X, y)\n",
                "\n",
                "print(\"First in-sample predictions:\", iowa_model.predict(X.head()))\n",
                "print(\"Actual target values for those homes:\", y.head().tolist())\n",
                "\n",
                "\n",
                "#### Import the train_test_split function and uncomment\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "#### fill in and uncomment\n",
                "train_X, val_X, train_y, val_y = train_test_split(X,y,random_state=1)\n",
                "\n",
                "\n",
                "\n",
                "#### Specify the model\n",
                "iowa_model = DecisionTreeRegressor(random_state=1)\n",
                "\n",
                "#### Fit iowa_model with the training data.\n",
                "iowa_model.fit(train_X,train_y)\n",
                "\n",
                "\n",
                "#### Predict with all validation observations\n",
                "val_predictions = iowa_model.predict(val_X)\n",
                "\n",
                "\n",
                "#### print the top few validation predictions\n",
                "print(val_predictions[:5])\n",
                "#### print the top few actual prices from validation data\n",
                "print(val_y[:5])\n",
                "\n",
                "\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "val_mae = mean_absolute_error(val_y, val_predictions)\n",
                "\n"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-59-53afa6bfc1e7>, line 26)",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-59-53afa6bfc1e7>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    First in-sample predictions: [208500. 181500. 223500. 140000. 250000.]\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "## Ansatz2\n",
                "#### Read the data\n",
                "X_full = pd.read_csv('../input/train.csv', index_col='Id')\n",
                "X_test_full = pd.read_csv('../input/test.csv', index_col='Id')\n",
                "\n",
                "#### Obtain target and predictors\n",
                "y = X_full.SalePrice\n",
                "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
                "X = X_full[features].copy()\n",
                "X_test = X_test_full[features].copy()\n",
                "\n",
                "#### Break off validation set from training data\n",
                "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
                "                                                      random_state=0)\n",
                "\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "\n",
                "#### Define the models\n",
                "model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
                "model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
                "model_3 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=0)\n",
                "model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n",
                "model_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n",
                "\n",
                "models = [model_1, model_2, model_3, model_4, model_5]\n",
                "\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "\n",
                "#### Function for comparing different models\n",
                "def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n",
                "    model.fit(X_t, y_t)\n",
                "    preds = model.predict(X_v)\n",
                "    return mean_absolute_error(y_v, preds)\n",
                "\n",
                "for i in range(0, len(models)):\n",
                "    mae = score_model(models[i])\n",
                "    print(\"Model %d MAE: %d\" % (i+1, mae))\n",
                "\n",
                "#### Fill in the best model\n",
                "best_model = model_3\n",
                "\n",
                "#### Define a model\n",
                "my_model = best_model \n",
                "#### Define a model\n",
                "my_model = best_model\n",
                "\n",
                "#### Fit the model to the training data\n",
                "my_model.fit(X, y)\n",
                "\n",
                "#### Generate test predictions\n",
                "preds_test = my_model.predict(X_test)\n",
                "\n",
                "#### Save predictions in format used for competition scoring\n",
                "output = pd.DataFrame({'Id': X_test.index,\n",
                "                       'SalePrice': preds_test})\n",
                "output.to_csv('submission.csv', index=False)"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] File b'../input/train.csv' does not exist: b'../input/train.csv'",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-98-1ff61cff34f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Ansatz2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#### Read the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_test_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../input/train.csv' does not exist: b'../input/train.csv'"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "## Ansatz3\n",
                "#### Import helpful libraries\n",
                "import pandas as pd\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "#### Load the data, and separate the target\n",
                "iowa_file_path = '../input/train.csv'\n",
                "home_data = pd.read_csv(iowa_file_path)\n",
                "y = home_data.SalePrice\n",
                "\n",
                "#### Create X (After completing the exercise, you can return to modify this line!)\n",
                "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
                "\n",
                "#### Select columns corresponding to features, and preview the data\n",
                "X = home_data[features]\n",
                "X.head()\n",
                "\n",
                "#### Split into validation and training data\n",
                "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
                "\n",
                "#### Define a random forest model\n",
                "rf_model = RandomForestRegressor(random_state=1)\n",
                "rf_model.fit(train_X, train_y)\n",
                "rf_val_predictions = rf_model.predict(val_X)\n",
                "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
                "\n",
                "print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\n",
                "\n",
                "#### To improve accuracy, create a new Random Forest model which you will train on all training data\n",
                "rf_model_on_full_data = RandomForestRegressor(random_state=2)\n",
                "\n",
                "\n",
                "#### fit rf_model_on_full_data on all data from the training data\n",
                "rf_model_on_full_data.fit(X,y)\n",
                "\n",
                "#### path to file you will use for predictions\n",
                "test_data_path = '../input/test.csv'\n",
                "\n",
                "#### read test data file using pandas\n",
                "test_data = pd.read_csv(test_data_path)\n",
                "\n",
                "#### create test_X which comes from test_data but includes only the columns you used for prediction.\n",
                "#### The list of columns is stored in a variable called features\n",
                "test_X = test_data[features]\n",
                "\n",
                "#### make predictions which we will submit. \n",
                "test_preds = rf_model_on_full_data.predict(test_X)\n",
                "test_preds\n",
                "\n",
                "output = pd.DataFrame({'Id': test_data.Id,\n",
                "                       'SalePrice': test_preds})\n",
                "output.to_csv('submission.csv', index=False)"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-62-8f2f342fc778>, line 1)",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-62-8f2f342fc778>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    This notebook is an exercise in the Introduction to Machine Learning course. You can reference the tutorial at this link.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "## Ansatz4\n",
                "#### Code you have previously used to load data\n",
                "import pandas as pd\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "\n",
                "\n",
                "#### Path of the file to read\n",
                "iowa_file_path = '../input/home-data-for-ml-course/train.csv'\n",
                "\n",
                "home_data = pd.read_csv(iowa_file_path)\n",
                "#### Create target object and call it y\n",
                "y = home_data.SalePrice\n",
                "#### Create X\n",
                "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
                "X = home_data[features]\n",
                "\n",
                "#### Split into validation and training data\n",
                "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
                "\n",
                "#### Specify Model\n",
                "iowa_model = DecisionTreeRegressor(random_state=1)\n",
                "#### Fit Model\n",
                "iowa_model.fit(train_X, train_y)\n",
                "\n",
                "#### Make validation predictions and calculate mean absolute error\n",
                "val_predictions = iowa_model.predict(val_X)\n",
                "val_mae = mean_absolute_error(val_predictions, val_y)\n",
                "print(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
                "\n",
                "#### Using best value for max_leaf_nodes\n",
                "iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\n",
                "iowa_model.fit(train_X, train_y)\n",
                "val_predictions = iowa_model.predict(val_X)\n",
                "val_mae = mean_absolute_error(val_predictions, val_y)\n",
                "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
                "\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "\n",
                "#### Define the model. Set random_state to 1\n",
                "rf_model = RandomForestRegressor(random_state=1)\n",
                "\n",
                "#### fit your model\n",
                "rf_model.fit(train_X,train_y)\n",
                "\n",
                "#### Calculate the mean absolute error of your Random Forest model on the validation data\n",
                "rf_val_mae = mean_absolute_error(val_y,rf_model.predict(val_X))\n",
                "\n",
                "print(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))\n",
                "\n",
                "\n",
                "rf_model = RandomForestRegressor()\n",
                "\n",
                "#### fit your model\n",
                "rf_model.fit(train_X, train_y)\n",
                "\n",
                "#### Calculate the mean absolute error of your Random Forest model on the validation data\n",
                "rf_val_predictions = rf_model.predict(val_X)\n",
                "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-63-45c6d3aa71f9>, line 1)",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-63-45c6d3aa71f9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    This notebook is an exercise in the Introduction to Machine Learning course. You can reference the tutorial at this link.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "## Ansatz5\n",
                "#### Code you have previously used to load data\n",
                "import pandas as pd\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.tree import DecisionTreeRegressor\n",
                "\n",
                "\n",
                "#### Path of the file to read\n",
                "iowa_file_path = '../input/home-data-for-ml-course/train.csv'\n",
                "\n",
                "home_data = pd.read_csv(iowa_file_path)\n",
                "#### Create target object and call it y\n",
                "y = home_data.SalePrice\n",
                "#### Create X\n",
                "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
                "X = home_data[features]\n",
                "\n",
                "#### Split into validation and training data\n",
                "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
                "\n",
                "#### Specify Model\n",
                "iowa_model = DecisionTreeRegressor(random_state=1)\n",
                "#### Fit Model\n",
                "iowa_model.fit(train_X, train_y)\n",
                "\n",
                "#### Make validation predictions and calculate mean absolute error\n",
                "val_predictions = iowa_model.predict(val_X)\n",
                "val_mae = mean_absolute_error(val_predictions, val_y)\n",
                "print(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
                "\n",
                "#### Using best value for max_leaf_nodes\n",
                "iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\n",
                "iowa_model.fit(train_X, train_y)\n",
                "val_predictions = iowa_model.predict(val_X)\n",
                "val_mae = mean_absolute_error(val_predictions, val_y)\n",
                "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
                "\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "\n",
                "#### Define the model. Set random_state to 1\n",
                "rf_model = RandomForestRegressor(random_state=1)\n",
                "\n",
                "#### fit your model\n",
                "rf_model.fit(train_X,train_y)\n",
                "\n",
                "#### Calculate the mean absolute error of your Random Forest model on the validation data\n",
                "rf_val_mae = mean_absolute_error(val_y,rf_model.predict(val_X))\n",
                "\n",
                "print(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))\n",
                "\n",
                "\n",
                "rf_model = RandomForestRegressor()\n",
                "\n",
                "#### fit your model\n",
                "rf_model.fit(train_X, train_y)\n",
                "\n",
                "#### Calculate the mean absolute error of your Random Forest model on the validation data\n",
                "rf_val_predictions = rf_model.predict(val_X)\n",
                "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-64-45c6d3aa71f9>, line 1)",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-45c6d3aa71f9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    This notebook is an exercise in the Introduction to Machine Learning course. You can reference the tutorial at this link.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "## Ansatz6 \n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "#### Read the data\n",
                "X = pd.read_csv('../input/train.csv', index_col='Id')\n",
                "X_test_full = pd.read_csv('../input/test.csv', index_col='Id')\n",
                "\n",
                "#### Remove rows with missing target, separate target from predictors\n",
                "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
                "y = X.SalePrice              \n",
                "X.drop(['SalePrice'], axis=1, inplace=True)\n",
                "\n",
                "#### Break off validation set from training data\n",
                "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
                "                                                                random_state=0)\n",
                "\n",
                "#### \"Cardinality\" means the number of unique values in a column\n",
                "#### Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
                "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
                "                        X_train_full[cname].dtype == \"object\"]\n",
                "\n",
                "#### Select numeric columns\n",
                "numeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
                "\n",
                "#### Keep selected columns only\n",
                "my_cols = low_cardinality_cols + numeric_cols\n",
                "X_train = X_train_full[my_cols].copy()\n",
                "X_valid = X_valid_full[my_cols].copy()\n",
                "X_test = X_test_full[my_cols].copy()\n",
                "\n",
                "#### One-hot encode the data (to shorten the code, we use pandas)\n",
                "X_train = pd.get_dummies(X_train)\n",
                "X_valid = pd.get_dummies(X_valid)\n",
                "X_test = pd.get_dummies(X_test)\n",
                "X_train, X_valid = X_train.align(X_valid, join='left', axis=1)\n",
                "X_train, X_test = X_train.align(X_test, join='left', axis=1)\n",
                "\n",
                "from xgboost import XGBRegressor\n",
                "\n",
                "#### Define the model\n",
                "my_model_1 = XGBRegressor(random_state=0) # Your code here\n",
                "\n",
                "#### Fit the model\n",
                "my_model_1.fit(X_train,y_train) # Your code here\n",
                "\n",
                "\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "\n",
                "#### Get predictions\n",
                "predictions_1 = my_model_1.predict(X_valid) # Your code here\n",
                "\n",
                "\n",
                "#### Calculate MAE\n",
                "mae_1 = mean_absolute_error(y_valid, predictions_1) # Your code here\n",
                "\n",
                "#### Uncomment to print MAE\n",
                "print(\"Mean Absolute Error:\" , mae_1)\n",
                " \n",
                "#### Define the model\n",
                "my_model_2 = XGBRegressor(n_estimators=1000,learning_rate=0.02, random_state=1) # Your code here\n",
                "\n",
                "#### Fit the model\n",
                "my_model_2.fit(X_train,y_train) # Your code here\n",
                "\n",
                "#### Get predictions\n",
                "predictions_2 = my_model_2.predict(X_valid) # Your code here\n",
                "\n",
                "#### Calculate MAE\n",
                "mae_2 = mean_absolute_error(y_valid, predictions_2) # Your code here\n",
                "\n",
                "#### Uncomment to print MAE\n",
                "print(\"Mean Absolute Error:\" , mae_2)\n",
                "mae_2<mae_1\n",
                "\n",
                "\n",
                "#### Step 3: Break the model\n",
                "\n",
                "#### Define the model\n",
                "my_model_3 = XGBRegressor(n_estimators=10000, early_stopping_rounds=20, random_state=3)\n",
                "\n",
                "#### Fit the model\n",
                "my_model_3.fit(X_train,y_train)# Your code here\n",
                "\n",
                "#### Get predictions\n",
                "predictions_3 = my_model_3.predict(X_valid)\n",
                "\n",
                "#### Calculate MAE\n",
                "mae_3 = mean_absolute_error(y_valid, predictions_3)\n",
                "\n",
                "#### Uncomment to print MAE\n",
                "print(\"Mean Absolute Error:\" , mae_3)\n",
                "\n"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] File b'../input/train.csv' does not exist: b'../input/train.csv'",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-104-8dd6957ee277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#### Read the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_test_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../input/train.csv' does not exist: b'../input/train.csv'"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "## Ansatz7\n",
                "\n",
                "\n",
                "#### Remove rows with missing target, separate target from predictors\n",
                "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
                "y = X_full.SalePrice\n",
                "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
                "\n",
                "#### Break off validation set from training data\n",
                "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
                "                                                                train_size=0.8, test_size=0.2,\n",
                "                                                                random_state=0)\n",
                "\n",
                "#### \"Cardinality\" means the number of unique values in a column\n",
                "#### Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
                "categorical_cols = [cname for cname in X_train_full.columns if\n",
                "                    X_train_full[cname].nunique() < 10 and \n",
                "                    X_train_full[cname].dtype == \"object\"]\n",
                "\n",
                "#### Select numerical columns\n",
                "numerical_cols = [cname for cname in X_train_full.columns if \n",
                "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
                "\n",
                "#### Keep selected columns only\n",
                "my_cols = categorical_cols + numerical_cols\n",
                "X_train = X_train_full[my_cols].copy()\n",
                "X_valid = X_valid_full[my_cols].copy()\n",
                "X_test = X_test_full[my_cols].copy()\n",
                "\n",
                "\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "\n",
                "#### Preprocessing for numerical data\n",
                "numerical_transformer = SimpleImputer(strategy='constant')\n",
                "\n",
                "#### Preprocessing for categorical data\n",
                "categorical_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
                "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
                "])\n",
                "\n",
                "#### Bundle preprocessing for numerical and categorical data\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', numerical_transformer, numerical_cols),\n",
                "        ('cat', categorical_transformer, categorical_cols)\n",
                "    ])\n",
                "\n",
                "#### Define model\n",
                "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
                "\n",
                "#### Bundle preprocessing and modeling code in a pipeline\n",
                "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                      ('model', model)\n",
                "                     ])\n",
                "\n",
                "#### Preprocessing of training data, fit model \n",
                "clf.fit(X_train, y_train)\n",
                "\n",
                "#### Preprocessing of validation data, get predictions\n",
                "preds = clf.predict(X_valid)\n",
                "\n",
                "\n",
                "\n",
                "#### Preprocessing for numerical data\n",
                "numerical_transformer = SimpleImputer(strategy='constant') # Your code here\n",
                "\n",
                "#### Preprocessing for categorical data\n",
                "from sklearn.preprocessing import OrdinalEncoder\n",
                "categorical_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
                "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
                "    \n",
                "]) \n",
                "\n",
                "\n",
                "#### Bundle preprocessing for numerical and categorical data\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', numerical_transformer, numerical_cols),\n",
                "        ('cat', categorical_transformer, categorical_cols)\n",
                "    ])\n",
                "\n",
                "#### Define model\n",
                "model = RandomForestRegressor(n_estimators=100, random_state=20) # Your code here\n",
                "\n",
                "\n",
                "#### Preprocessing for numerical data\n",
                "numerical_transformer = SimpleImputer(strategy='constant')\n",
                "\n",
                "#### Preprocessing for categorical data\n",
                "categorical_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='constant')),\n",
                "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
                "])\n",
                "\n",
                "#### Bundle preprocessing for numerical and categorical data\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', numerical_transformer, numerical_cols),\n",
                "        ('cat', categorical_transformer, categorical_cols)\n",
                "    ])\n",
                "\n",
                "#### Define model\n",
                "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
                "\n",
                "#### Bundle preprocessing and modeling code in a pipeline\n",
                "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                              ('model', model)\n",
                "                             ])\n",
                "\n",
                "#### Preprocessing of training data, fit model \n",
                "my_pipeline.fit(X_train, y_train)\n",
                "\n",
                "#### Preprocessing of validation data, get predictions\n",
                "preds = my_pipeline.predict(X_valid)\n",
                "\n",
                "#### Evaluate the model\n",
                "score = mean_absolute_error(y_valid, preds)\n",
                "print('MAE:', score)\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "Step 2: Generate test predictions\n",
                "\n",
                "\n",
                "#### Preprocessing of test data, fit model\n",
                "preds_test = my_pipeline.predict(X_test) \n",
                "\n",
                "\n",
                "\n",
                "#### Preprocessing of test data, fit model\n",
                "preds_test = my_pipeline.predict(X_test)\n",
                "\n",
                "#### Save test predictions to file\n",
                "output = pd.DataFrame({'Id': X_test.index,\n",
                "                       'SalePrice': preds_test})\n",
                "output.to_csv('submission.csv', index=False)"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-66-f29c935557cf>, line 1)",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-f29c935557cf>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    This notebook is an exercise in the Intermediate Machine Learning course. You can reference the tutorial at this link.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Ansatz 8\n",
                "\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "#### Read the data\n",
                "X_full = pd.read_csv('../input/train.csv', index_col='Id')\n",
                "X_test_full = pd.read_csv('../input/test.csv', index_col='Id')\n",
                "\n",
                "#### Remove rows with missing target, separate target from predictors\n",
                "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
                "y = X_full.SalePrice\n",
                "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
                "\n",
                "#### To keep things simple, we'll use only numerical predictors\n",
                "X = X_full.select_dtypes(exclude=['object'])\n",
                "X_test = X_test_full.select_dtypes(exclude=['object'])\n",
                "\n",
                "#### Break off validation set from training data\n",
                "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
                "                                                      random_state=0)\n",
                "\n",
                "\n",
                "# Shape of training data (num_rows, num_columns)\n",
                "print(X_train.shape)\n",
                "\n",
                "# Number of missing values in each column of training data\n",
                "missing_val_count_by_column = (X_train.isnull().sum())\n",
                "print(missing_val_count_by_column[missing_val_count_by_column > 0])\n",
                "\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "\n",
                "# Function for comparing different approaches\n",
                "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
                "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
                "    model.fit(X_train, y_train)\n",
                "    preds = model.predict(X_valid)\n",
                "    return mean_absolute_error(y_valid, preds)\n",
                "\n",
                "# Fill in the line below: get names of columns with missing values\n",
                "miss_col = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
                "miss_col\n",
                "\n",
                "# Fill in the lines below: drop columns in training and validation data\n",
                "reduced_X_train = X_train.drop(miss_col, axis=1) # 1 axis as in cols\n",
                "reduced_X_valid = X_valid.drop(miss_col, axis=1)\n",
                "\n",
                "print(\"MAE (Drop columns with missing values):\")\n",
                "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))\n",
                "\n",
                "\n",
                "from sklearn.impute import SimpleImputer\n",
                "\n",
                "# Fill in the lines below: imputation\n",
                "____ # Your code here\n",
                "impute=SimpleImputer()\n",
                "imputed_X_train = pd.DataFrame(impute.fit_transform(X_train))\n",
                "imputed_X_valid = pd.DataFrame(impute.transform(X_valid))\n",
                "\n",
                "# Fill in the lines below: imputation removed column names; put them back\n",
                "imputed_X_train.columns = X_train.columns\n",
                "imputed_X_valid.columns = X_valid.columns\n",
                "\n",
                "# Imputation\n",
                "my_imputer = SimpleImputer()\n",
                "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
                "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
                "\n",
                "# Imputation removed column names; put them back\n",
                "imputed_X_train.columns = X_train.columns\n",
                "imputed_X_valid.columns = X_valid.columns\n",
                "Run the next code cell without changes to obtain the MAE for this approach.\n",
                "\n",
                "print(\"MAE (Imputation):\")\n",
                "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))\n",
                "M\n",
                "\n",
                "# Preprocessed training and validation features\n",
                "final_X_train = reduced_X_train\n",
                "final_X_valid = reduced_X_valid\n",
                "\n",
                "# Define and fit model\n",
                "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
                "model.fit(final_X_train, y_train)\n",
                "\n",
                "# Get validation predictions and MAE\n",
                "preds_valid = model.predict(final_X_valid)\n",
                "print(\"MAE (Your approach):\")\n",
                "print(mean_absolute_error(y_valid, preds_valid))\n",
                "\n",
                "\n",
                "# Fill in the line below: preprocess test data\n",
                "impute_X_test= pd.DataFrame(impute.transform(X_test))\n",
                "impute_X_test.columns = X_test.columns\n",
                "\n",
                "final_X_test = impute_X_test.drop(miss_col, axis=1)\n",
                "\n",
                "# Fill in the line below: get test predictions\n",
                "preds_test = model.predict(final_X_test)\n",
                "\n",
                "\n",
                "# Preprocess test data\n",
                "final_X_test = pd.DataFrame(final_imputer.transform(X_test))\n",
                "\n",
                "# Get test predictions\n",
                "preds_test = model.predict(final_X_test)\n",
                "\n",
                "# Save test predictions to file\n",
                "output = pd.DataFrame({'Id': X_test.index,\n",
                "                       'SalePrice': preds_test})\n",
                "output.to_csv('submission.csv', index=False)\n",
                "X_test.index"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-67-3060d175032b>, line 1)",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-67-3060d175032b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    This notebook is an exercise in the Intermediate Machine Learning course. You can reference the tutorial at this link.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "## Ansatz9\n",
                "\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Read the data\n",
                "X_full = pd.read_csv('../input/train.csv', index_col='Id')\n",
                "X_test_full = pd.read_csv('../input/test.csv', index_col='Id')\n",
                "\n",
                "# Remove rows with missing target, separate target from predictors\n",
                "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
                "y = X_full.SalePrice\n",
                "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
                "\n",
                "# To keep things simple, we'll use only numerical predictors\n",
                "X = X_full.select_dtypes(exclude=['object'])\n",
                "X_test = X_test_full.select_dtypes(exclude=['object'])\n",
                "\n",
                "# Break off validation set from training data\n",
                "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
                "                                                      random_state=0)\n",
                "\n",
                "\n",
                "# Shape of training data (num_rows, num_columns)\n",
                "print(X_train.shape)\n",
                "\n",
                "# Number of missing values in each column of training data\n",
                "missing_val_count_by_column = (X_train.isnull().sum())\n",
                "print(missing_val_count_by_column[missing_val_count_by_column > 0])\n",
                "\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "\n",
                "# Function for comparing different approaches\n",
                "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
                "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
                "    model.fit(X_train, y_train)\n",
                "    preds = model.predict(X_valid)\n",
                "    return mean_absolute_error(y_valid, preds)\n",
                "\n",
                "# Fill in the line below: get names of columns with missing values\n",
                "miss_col = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
                "miss_col\n",
                "\n",
                "# Fill in the lines below: drop columns in training and validation data\n",
                "reduced_X_train = X_train.drop(miss_col, axis=1) # 1 axis as in cols\n",
                "reduced_X_valid = X_valid.drop(miss_col, axis=1)\n",
                "\n",
                "\n",
                "In [13]:\n",
                "print(\"MAE (Drop columns with missing values):\")\n",
                "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))\n",
                "\n",
                "\n",
                "from sklearn.impute import SimpleImputer\n",
                "\n",
                "# Fill in the lines below: imputation\n",
                "____ # Your code here\n",
                "impute=SimpleImputer()\n",
                "imputed_X_train = pd.DataFrame(impute.fit_transform(X_train))\n",
                "imputed_X_valid = pd.DataFrame(impute.transform(X_valid))\n",
                "\n",
                "# Fill in the lines below: imputation removed column names; put them back\n",
                "imputed_X_train.columns = X_train.columns\n",
                "imputed_X_valid.columns = X_valid.columns\n",
                "\n",
                "\n",
                "# Imputation\n",
                "my_imputer = SimpleImputer()\n",
                "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
                "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
                "\n",
                "# Imputation removed column names; put them back\n",
                "imputed_X_train.columns = X_train.columns\n",
                "imputed_X_valid.columns = X_valid.columns\n",
                "\n",
                "print(\"MAE (Imputation):\")\n",
                "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))\n",
                "re are so few missing values in the dataset, we'd expect imputation to perform better than dropping columns entirely. However, we see that dropping columns performs slightly better! While this can probably partially be attributed to noise in the dataset, another potential explanation is that the imputation method is not a great match to this dataset. That is, maybe instead of filling in the mean value, it makes more sense to set every missing value to a value of 0, to fill in the most frequently encountered value, or to use some other method. For instance, consider the GarageYrBlt column (which indicates the year that the garage was built). It's likely that in some cases, a missing value could indicate a house that does not have a garage. Does it make more sense to fill in the median value along each column in this case? Or could we get better results by filling in the minimum value along each column? It's not quite clear what's best in this case, but perhaps we can rule out some options immediately - for instance, setting missing values in this column to 0 is likely to yield horrible results!\n",
                "\n",
                "# Preprocessed training and validation features\n",
                "final_X_train = reduced_X_train\n",
                "final_X_valid = reduced_X_valid\n",
                "\n",
                "# Define and fit model\n",
                "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
                "model.fit(final_X_train, y_train)\n",
                "\n",
                "# Get validation predictions and MAE\n",
                "preds_valid = model.predict(final_X_valid)\n",
                "print(\"MAE (Your approach):\")\n",
                "\n",
                "# Fill in the line below: preprocess test data\n",
                "impute_X_test= pd.DataFrame(impute.transform(X_test))\n",
                "impute_X_test.columns = X_test.columns\n",
                "\n",
                "final_X_test = impute_X_test.drop(miss_col, axis=1)\n",
                "\n",
                "# Fill in the line below: get test predictions\n",
                "preds_test = model.predict(final_X_test)\n",
                "\n",
                "\n",
                "\n",
                "# Preprocess test data\n",
                "final_X_test = pd.DataFrame(final_imputer.transform(X_test))\n",
                "\n",
                "# Get test predictions\n",
                "preds_test = model.predict(final_X_test)\n",
                "\n",
                "# Save test predictions to file\n",
                "output = pd.DataFrame({'Id': X_test.index,\n",
                "                       'SalePrice': preds_test})\n",
                "output.to_csv('submission.csv', index=False)\n",
                "X_test.index"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-68-a2a2089fb692>, line 1)",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-a2a2089fb692>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    This notebook is an exercise in the Intermediate Machine Learning course. You can reference the tutorial at this link.\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "## Ansatz 10\n",
                "\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "#### Read the data\n",
                "X = pd.read_csv('../input/train.csv', index_col='Id') \n",
                "X_test = pd.read_csv('../input/test.csv', index_col='Id')\n",
                "\n",
                "#### Remove rows with missing target, separate target from predictors\n",
                "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
                "y = X.SalePrice\n",
                "X.drop(['SalePrice'], axis=1, inplace=True)\n",
                "\n",
                "#### To keep things simple, we'll drop columns with missing values\n",
                "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
                "print(cols_with_missing)\n",
                "X.drop(cols_with_missing, axis=1, inplace=True)\n",
                "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
                "#X_test.drop(cols_with_missing, axis=1)\n",
                "#print(X_test.isnull().sum())\n",
                "# Break off validation set from training data\n",
                "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
                "                                                      train_size=0.8, test_size=0.2,\n",
                "                                                      random_state=0)\n",
                "['LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
                "\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_absolute_error\n",
                "\n",
                "# function for comparing different approaches\n",
                "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
                "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
                "    model.fit(X_train, y_train)\n",
                "    preds = model.predict(X_valid)\n",
                "    return mean_absolute_error(y_valid, preds)\n",
                "\n",
                "# Fill in the lines below: drop columns in training and validation data\n",
                "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
                "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
                "\n",
                "\n",
                "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
                "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))\n",
                "MAE from Approach 1 (Drop categorical variables):\n",
                "17837.82570776256\n",
                "Before jumping into ordinal encoding, we'll investigate the dataset. Specifically, we'll look at the 'Condition2' column. The code cell below prints the unique entries in both the training and validation sets.\n",
                "\n",
                "In [8]:\n",
                "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
                "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())\n",
                "\n",
                "\n",
                "In [11]:\n",
                "#### All categorical columns\n",
                "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
                "\n",
                "#### Columns that can be safely ordinal encoded\n",
                "good_label_cols = [col for col in object_cols if \n",
                "                   set(X_valid[col]).issubset(set(X_train[col]))]\n",
                "        \n",
                "#### Problematic columns that will be dropped from the dataset\n",
                "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
                "        \n",
                "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
                "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)\n",
                "\n",
                "\n",
                "from sklearn.preprocessing import OrdinalEncoder\n",
                "\n",
                "#### Drop categorical columns that will not be encoded\n",
                "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
                "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
                "\n",
                "#### Apply ordinal encoder \n",
                "____ #### Your code here\n",
                "oe = OrdinalEncoder()\n",
                "label_X_train[good_label_cols] = oe.fit_transform(X_train[good_label_cols])\n",
                "label_X_valid[good_label_cols] = oe.transform(X_valid[good_label_cols])\n",
                "\n",
                "\n",
                "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
                "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))\n",
                "\n",
                "\n",
                "#### Get number of unique entries in each column with categorical data\n",
                "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
                "d = dict(zip(object_cols, object_nunique))\n",
                "\n",
                "#### Print number of unique entries by column, in ascending order\n",
                "sorted(d.items(), key=lambda x: x[1])\n",
                "\n",
                "[('Street', 2),\n",
                " ('Utilities', 2),\n",
                " ('CentralAir', 2),\n",
                " ('LandSlope', 3),\n",
                " ('PavedDrive', 3),\n",
                " ('LotShape', 4),\n",
                " ('LandContour', 4),\n",
                " ('ExterQual', 4),\n",
                " ('KitchenQual', 4),\n",
                " ('MSZoning', 5),\n",
                " ('LotConfig', 5),\n",
                " ('BldgType', 5),\n",
                " ('ExterCond', 5),\n",
                " ('HeatingQC', 5),\n",
                " ('Condition2', 6),\n",
                " ('RoofStyle', 6),\n",
                " ('Foundation', 6),\n",
                " ('Heating', 6),\n",
                " ('Functional', 6),\n",
                " ('SaleCondition', 6),\n",
                " ('RoofMatl', 7),\n",
                " ('HouseStyle', 8),\n",
                " ('Condition1', 9),\n",
                " ('SaleType', 9),\n",
                " ('Exterior1st', 15),\n",
                " ('Exterior2nd', 16),\n",
                " ('Neighborhood', 25)]\n",
                "\n",
                "#### Fill in the line below: How many categorical variables in the training data\n",
                "#### have cardinality greater than 10?\n",
                "high_cardinality_numcols = 3\n",
                "\n",
                "#### Fill in the line below: How many columns are needed to one-hot encode the \n",
                "#### 'Neighborhood' variable in the training data?\n",
                "num_cols_neighborhood = 25\n",
                "\n",
                "\n",
                "#### Fill in the line below: How many entries are added to the dataset by \n",
                "#### replacing the column with a one-hot encoding?\n",
                "OH_entries_added = 10_000_00-10000\n",
                "\n",
                "#### Fill in the line below: How many entries are added to the dataset by\n",
                "#### replacing the column with an ordinal encoding?\n",
                "label_entries_added = 0\n",
                "\n",
                "\n",
                "#### Columns that will be one-hot encoded\n",
                "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
                "\n",
                "#### Columns that will be dropped from the dataset\n",
                "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
                "\n",
                "\n",
                "\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "\n",
                "#### Use as many lines of code as you need!\n",
                "\n",
                "OHE = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n",
                "\n",
                "OH_cols_train = pd.DataFrame(OHE.fit_transform(X_train[low_cardinality_cols])) # Your code here\n",
                "OH_cols_valid = pd.DataFrame(OHE.transform(X_valid[low_cardinality_cols])) # Your code here\n",
                "\n",
                "OH_cols_train.index = X_train.index\n",
                "OH_cols_valid.index = X_valid.index\n",
                "\n",
                "num_X_train = X_train.drop(object_cols,axis=1)\n",
                "num_X_valid= X_valid.drop(object_cols,axis=1)\n",
                "\n",
                "OH_X_train = pd.concat([num_X_train,OH_cols_train], axis=1)\n",
                "OH_X_valid = pd.concat([num_X_valid,OH_cols_valid], axis=1)\n",
                "\n",
                "\n",
                "#### Apply one-hot encoder to each column with categorical data\n",
                "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
                "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
                "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
                "\n",
                "#### One-hot encoding removed index; put it back\n",
                "OH_cols_train.index = X_train.index\n",
                "OH_cols_valid.index = X_valid.index\n",
                "\n",
                "#### Remove categorical columns (will replace with one-hot encoding)\n",
                "num_X_train = X_train.drop(object_cols, axis=1)\n",
                "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
                "\n",
                "#### Add one-hot encoded columns to numerical features\n",
                "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
                "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
                "\n",
                "\n",
                "In [23]:\n",
                "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
                "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))\n",
                "\n",
                "\n",
                "In [24]:\n",
                "#### (Optional) Your code here\n",
                "'''from sklearn.preprocessing import OrdinalEncoder\n",
                "\n",
                "# Drop categorical columns that will not be encoded\n",
                "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
                "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
                "\n",
                "# Apply ordinal encoder \n",
                "____ # Your code here\n",
                "oe = OrdinalEncoder()\n",
                "label_X_train[good_label_cols] = oe.fit_transform(X_train[good_label_cols])\n",
                "label_X_valid[good_label_cols] = oe.transform(X_valid[good_label_cols])\n",
                "\n",
                "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
                "model.fit(label_X_train, y_train)\n",
                "preds = model.predict(label_X_valid)\n",
                "mae = mean_absolute_error(y_valid, preds)\n",
                "\n",
                "X_new=X_test.copy()\n",
                "X_new=X_new.drop(bad_label_cols,axis=1)\n",
                "\n",
                "\n",
                "num_X = X_new.drop(good_label_cols, axis=1)\n",
                "\n",
                "from sklearn.impute import SimpleImputer\n",
                "si = SimpleImputer()\n",
                "imputed_num_X = pd.DataFrame(si.fit_transform(num_X)) #why fit here? just transform didnt work\n",
                "imputed_num_X.columns = num_X.columns\n",
                "\n",
                "label_X_test = X_test.copy()\n",
                "\n",
                "label_X_test = label_X_test.select_dtypes(exclude=['int64','float64'])\n",
                "\n",
                "label_X_test = label_X_test.drop(bad_label_cols, axis=1)\n",
                "label_X_test.isnull().sum()\n",
                "#label_X_test[good_label_cols] = oe.transform(label_X_test[good_label_cols])'''\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
                "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
                "\n",
                "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
                "model.fit(drop_X_train, y_train)\n",
                "preds = model.predict(drop_X_valid)\n",
                "mae= mean_absolute_error(y_valid, preds)\n",
                "\n",
                "drop_X_test = X_test.select_dtypes(exclude=['object'])\n",
                "\n",
                "from sklearn.impute import SimpleImputer\n",
                "\n",
                "si = SimpleImputer()\n",
                "\n",
                "idXt = pd.DataFrame(si.fit_transform(drop_X_test))\n",
                "\n",
                "idXt.columns = drop_X_test.columns\n",
                "\n",
                "predict_test = model.predict(idXt)\n",
                "\n",
                "output = pd.DataFrame ( {'Id':X_test.index, 'SalePrice':predict_test})\n",
                "output.to_csv('submission_nothappy_droppedcatvar_NaNinCatVar_cantimpute.csv', index=False)\n"
            ],
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "IndentationError",
                    "evalue": "unindent does not match any outer indentation level (<tokenize>, line 193)",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m193\u001b[0m\n\u001b[0;31m    ('Utilities', 2),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.4",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.4 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "5bb92a85c9a1f15da6b689aacf75061d89825faba8bdf21749792174943e74b5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}